import streamlit as st
from PIL import Image
import io
import time

# ==============================================================================
# IMPORTA√á√ÉO SEGURA DE BIBLIOTECAS (DUAL MODE)
# ==============================================================================
try:
    import vertexai
    from vertexai.generative_models import GenerativeModel as VertexModel, Part, Image as VertexImage
    VERTEX_LIB_AVAILABLE = True
except ImportError:
    VERTEX_LIB_AVAILABLE = False

try:
    import google.generativeai as genai
    STUDIO_LIB_AVAILABLE = True
except ImportError:
    STUDIO_LIB_AVAILABLE = False

# ==============================================================================
# CONFIGURA√á√ÉO DA P√ÅGINA
# ==============================================================================
st.set_page_config(
    page_title="Clarity Engine - Gerador de Artefatos",
    page_icon="üéØ",
    layout="wide"
)

# Inicializa o Buffer na Sess√£o
if 'dossie_buffer' not in st.session_state:
    st.session_state.dossie_buffer = [] 

# ==============================================================================
# CAMADA 1: ACUMULADOR DE CONTEXTO
# ==============================================================================
class ContextAccumulator:
    @staticmethod
    def add_image(uploaded_file):
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            st.session_state.dossie_buffer.append({
                'type': 'image',
                'content': image,
                'label': uploaded_file.name
            })
            st.toast(f"üì∏ Imagem '{uploaded_file.name}' adicionada!")

    @staticmethod
    def add_text(text_input):
        if text_input and text_input.strip():
            st.session_state.dossie_buffer.append({
                'type': 'text',
                'content': text_input,
                'label': f"Nota ({len(text_input)} chars)"
            })
            st.toast("üìù Texto adicionado!")

    @staticmethod
    def clear_buffer():
        st.session_state.dossie_buffer = []
        st.toast("üóëÔ∏è Dossi√™ limpo.")

# ==============================================================================
# CAMADA 2: ENGENHARIA DE PROMPT
# ==============================================================================
class PromptEngine:
    @staticmethod
    def get_system_instruction(artifact_type):
        base_instruction = """
        ATUE COMO: Product Owner T√©cnico e Engenheiro de Software S√™nior.
        CONTEXTO: Voc√™ receber√° evid√™ncias visuais (telas, mockups, erros) e textuais.
        OBJETIVO: Gerar um artefato de trabalho detalhado para o time de desenvolvimento √°gil.
        """
        
        if artifact_type == "PBI (Product Backlog Item)":
            return base_instruction + """
            SA√çDA ESPERADA: Um PBI (User Story) completo contendo:
            1. T√≠tulo conciso (Valor de Neg√≥cio).
            2. Descri√ß√£o (Formato: Como [persona], quero [a√ß√£o], para que [benef√≠cio]).
            3. Crit√©rios de Aceite (Lista numerada, cobrindo cen√°rios felizes e de exce√ß√£o).
            4. Defini√ß√£o de Pronto (DoD) sugerida para este item espec√≠fico.
            5. Gherkin (Dado/Quando/Ent√£o) para os principais cen√°rios de teste.
            """
        elif artifact_type == "Task T√©cnica (Sub-tarefa de PBI)":
            return base_instruction + """
            SA√çDA ESPERADA: Uma Task T√©cnica para desenvolvedores contendo:
            1. Objetivo T√©cnico (O que deve ser codificado/alterado).
            2. Altera√ß√µes Necess√°rias (Frontend, Backend, Banco de Dados, APIs).
            3. Sugest√£o de endpoints, payloads JSON ou estruturas de dados.
            4. Passos de Implementa√ß√£o recomendados.
            """
        elif artifact_type == "Bug / Defeito":
            return base_instruction + """
            SA√çDA ESPERADA: Um Relat√≥rio de Bug profissional contendo:
            1. T√≠tulo do Defeito.
            2. Passos para Reprodu√ß√£o (baseado na an√°lise visual das evid√™ncias).
            3. Comportamento Esperado vs. Comportamento Atual (Observado).
            4. Hip√≥tese da Causa Raiz (An√°lise t√©cnica baseada no erro visual/log).
            5. Severidade Sugerida e Impacto.
            """
        return base_instruction

    @staticmethod
    def assemble_payload_vertex(artifact_type):
        payload = [PromptEngine.get_system_instruction(artifact_type)]
        for item in st.session_state.dossie_buffer:
            if item['type'] == 'text':
                payload.append(f"\nCONTEXTO ADICIONAL: {item['content']}\n")
            elif item['type'] == 'image':
                img_byte_arr = io.BytesIO()
                item['content'].save(img_byte_arr, format='PNG')
                payload.append(VertexImage.from_bytes(img_byte_arr.getvalue()))
        return payload

    @staticmethod
    def assemble_payload_studio(artifact_type):
        payload = [PromptEngine.get_system_instruction(artifact_type)]
        for item in st.session_state.dossie_buffer:
            if item['type'] == 'text':
                payload.append(f"\nCONTEXTO ADICIONAL: {item['content']}\n")
            elif item['type'] == 'image':
                payload.append(item['content']) 
        return payload

# ==============================================================================
# CAMADA 3: S√çNTESE (Dual Mode)
# ==============================================================================

class VertexSynthesis:
    def __init__(self, project_id, location):
        self.project_id = project_id
        # Define a localiza√ß√£o (padr√£o 'us-central1' ou 'global' para previews)
        self.location = location 
        
        if VERTEX_LIB_AVAILABLE:
            try:
                # Inicializa√ß√£o expl√≠cita
                vertexai.init(project=project_id, location=location)
                self.initialized = True
            except Exception as e:
                st.error(f"Erro ao iniciar Vertex AI: {e}")
                self.initialized = False
        else:
            st.error("Biblioteca `google-cloud-aiplatform` n√£o instalada.")
            self.initialized = False

    def generate(self, artifact_type, model_name):
        if not self.initialized: return "Erro: Vertex AI n√£o inicializado."
        try:
            model = VertexModel(model_name)
            payload = PromptEngine.assemble_payload_vertex(artifact_type)
            
            response = model.generate_content(
                payload, 
                generation_config={"temperature": 0.2, "max_output_tokens": 8192}
            )
            return response.text
        except Exception as e:
            error_msg = str(e)
            
            st.error("‚ö†Ô∏è Falha na Vertex AI. Detalhes t√©cnicos abaixo:")
            with st.expander("Ver Log de Erro Completo (Para Debug)"):
                st.code(error_msg)

            if "404" in error_msg and "not found" in error_msg:
                return f"""
                ‚ùå **Modelo ou Regi√£o Inv√°lida**
                
                O modelo `{model_name}` n√£o foi encontrado na regi√£o `{self.location}`.
                
                **Poss√≠veis Solu√ß√µes:**
                1. Se estiver usando modelos "Preview" (como Gemini 3), tente mudar a **Regi√£o** para `global` ou certifique-se que o modelo existe.
                2. Verifique se o seu projeto GCP tem acesso a esses modelos (alguns exigem ativa√ß√£o manual no Model Garden).
                """
            
            if "BILLING_DISABLED" in error_msg:
                return "‚ùå Erro de Faturamento: Ative o Billing no Console do Google Cloud."
            
            return f"‚ùå Erro Gen√©rico: {error_msg}"

class CorporateSynthesis:
    def __init__(self, api_key, base_url=None):
        self.api_key = api_key
        self.base_url = base_url
        if STUDIO_LIB_AVAILABLE:
            genai.configure(api_key=api_key)
            self.initialized = True
        else:
            st.error("Biblioteca `google-generativeai` n√£o instalada.")
            self.initialized = False

    def generate(self, artifact_type, model_name):
        if not self.initialized: return "Erro de Lib."
        if not self.api_key: return "Erro: API Key vazia."
        try:
            # Normaliza√ß√£o inteligente de modelos para API Key (AI Studio)
            # O AI Studio pode n√£o reconhecer 'gemini-3-pro-preview' exatamente como a Vertex
            # Tentamos manter o nome, mas se falhar, o usu√°rio deve ajustar.
            
            model = genai.GenerativeModel(model_name)
            payload = PromptEngine.assemble_payload_studio(artifact_type)
            response = model.generate_content(
                payload,
                generation_config={"temperature": 0.2, "max_output_tokens": 8192}
            )
            return response.text
        except Exception as e:
            return f"‚ùå Erro AI Studio: {str(e)}"

# ==============================================================================
# INTERFACE DO USU√ÅRIO
# ==============================================================================
def main():
    with st.sidebar:
        st.title("‚öôÔ∏è Configura√ß√£o")
        
        env_mode = st.radio(
            "Ambiente de Execu√ß√£o",
            ["Projeto Acad√™mico (GCP Vertex AI)", "Integra√ß√£o Corporativa (API Key)"],
        )
        
        st.divider()
        auth_config = {}
        
        if env_mode == "Projeto Acad√™mico (GCP Vertex AI)":
            st.info("Autentica√ß√£o: `gcloud auth`")
            auth_config['project_id'] = st.text_input("GCP Project ID", placeholder="ex: clarity-engine")
            
            # --- SELETOR DE REGI√ÉO REATIVADO ---
            # Modelos Preview (Gemini 3) muitas vezes exigem regions espec√≠ficas ou global.
            auth_config['location'] = st.selectbox(
                "Regi√£o (Vertex AI)",
                ["us-central1", "global"],
                index=0,
                help="Use 'us-central1' para modelos est√°veis. Tente 'global' se os modelos Preview (Gemini 3) falharem."
            )
            auth_config['mode'] = 'vertex'
            
        else:
            st.info("Autentica√ß√£o: API Key")
            auth_config['api_key'] = st.text_input("API Key", type="password")
            auth_config['base_url'] = st.text_input("Base URL (Opcional)")
            auth_config['mode'] = 'corporate'

        st.divider()
        
        # --- LISTA ATUALIZADA (GEMINI 3 e 2.5) ---
        # IDs oficiais de preview (baseado na documenta√ß√£o Vertex AI Model Garden)
        model_choice = st.selectbox(
            "Modelo Gemini (Vertex/Studio)", 
            [
                "gemini-3-pro-preview",    # √öltima gera√ß√£o (Racioc√≠nio Avan√ßado)
                "gemini-3-flash-preview",  # √öltima gera√ß√£o (Velocidade)
                "gemini-2.5-flash",        # Gera√ß√£o 2.5 Est√°vel
                "gemini-2.5-pro",          # Gera√ß√£o 2.5 Est√°vel
            ],
            index=0,
            help="Certifique-se de que seu projeto tem acesso a estes modelos no Model Garden."
        )

    st.title("üéØ Clarity Engine")
    st.caption(f"Ambiente: **{env_mode}** | Regi√£o: **{auth_config.get('location', 'Global/Auto')}**")

    col_left, col_right = st.columns([1, 1])

    with col_left:
        st.subheader("1. Acumulador")
        tab_img, tab_txt = st.tabs(["üì∏ Imagem", "üìù Texto"])
        with tab_img:
            u_img = st.file_uploader("Upload", type=['png', 'jpg', 'jpeg'])
            if u_img and st.button("‚ûï Add Imagem"): ContextAccumulator.add_image(u_img)
        with tab_txt:
            u_txt = st.text_area("Texto/Log", height=100)
            if st.button("‚ûï Add Texto"): ContextAccumulator.add_text(u_txt)

        if st.session_state.dossie_buffer:
            st.info(f"{len(st.session_state.dossie_buffer)} itens no buffer.")
            if st.button("Limpar"): 
                ContextAccumulator.clear_buffer()
                st.rerun()

    with col_right:
        st.subheader("2. Gerar")
        artifact_type = st.radio("Tipo", ["PBI", "Task T√©cnica", "Bug / Defeito"])
        
        if st.button("üöÄ Processar", type="primary", use_container_width=True):
            if not st.session_state.dossie_buffer:
                st.warning("Adicione evid√™ncias primeiro.")
            else:
                with st.spinner("Processando..."):
                    result = None
                    if auth_config['mode'] == 'vertex':
                        if not auth_config['project_id']:
                            st.error("Falta o Project ID.")
                        else:
                            bot = VertexSynthesis(auth_config['project_id'], auth_config['location'])
                            result = bot.generate(artifact_type, model_choice)
                    else:
                        if not auth_config['api_key']:
                            st.error("Falta a API Key.")
                        else:
                            bot = CorporateSynthesis(auth_config['api_key'], auth_config.get('base_url'))
                            result = bot.generate(artifact_type, model_choice)

                    if result and not result.startswith("‚ùå") and not result.startswith("Erro"):
                        st.success("Sucesso!")
                        st.markdown(result)
                        st.download_button("Download .md", result, file_name="doc.md")
                    elif result:
                        if "‚ùå" not in result: st.error(result)

if __name__ == "__main__":
    main()